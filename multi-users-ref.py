"""
PDF ê¸°ë°˜ ë©€í‹°ìœ ì € ë©€í‹°ì„¸ì…˜ RAG ì±—ë´‡
Supabaseë¥¼ í™œìš©í•œ ë©€í‹°ìœ ì € ë¡œê·¸ì¸ ë° ì„¸ì…˜ ì €ì¥/ë¡œë“œ ê¸°ëŠ¥
"""

import os
import streamlit as st
import tempfile
from datetime import datetime
from typing import List, Optional, Dict, Any, Tuple
import logging
import re
import uuid
import json
import hashlib

# LangChain ê´€ë ¨ ì„í¬íŠ¸
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.documents import Document
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

# Supabase ì„í¬íŠ¸
from supabase import create_client, Client

# Anthropic, Google ì„í¬íŠ¸
try:
    from langchain_anthropic import ChatAnthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

try:
    from langchain_google_genai import ChatGoogleGenerativeAI
    GOOGLE_AVAILABLE = True
except ImportError:
    GOOGLE_AVAILABLE = False

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.WARNING)
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("httpcore").setLevel(logging.WARNING)
logging.getLogger("openai").setLevel(logging.WARNING)

logger = logging.getLogger(__name__)

# ============================================
# Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
# ============================================
def init_supabase_client() -> Optional[Client]:
    """Supabase í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    supabase_url = os.getenv("SUPABASE_URL")
    supabase_key = os.getenv("SUPABASE_ANON_KEY") or os.getenv("SUPABASE_KEY")
    
    if not supabase_url or not supabase_key:
        return None
    
    try:
        client = create_client(supabase_url, supabase_key)
        return client
    except Exception as e:
        logger.error(f"Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None

# ============================================
# ì‚¬ìš©ì ì¸ì¦ í•¨ìˆ˜
# ============================================
def hash_password(password: str) -> str:
    """ë¹„ë°€ë²ˆí˜¸ë¥¼ í•´ì‹œí™”í•©ë‹ˆë‹¤."""
    return hashlib.sha256(password.encode()).hexdigest()

def register_user(username: str, password: str) -> Tuple[bool, str]:
    """ìƒˆ ì‚¬ìš©ìë¥¼ ë“±ë¡í•©ë‹ˆë‹¤."""
    if not st.session_state.supabase_client:
        return False, "Supabase ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤."
    
    try:
        # ë¹„ë°€ë²ˆí˜¸ í•´ì‹œí™”
        password_hash = hash_password(password)
        
        # users í…Œì´ë¸”ì— ì‚¬ìš©ì ì¶”ê°€
        response = st.session_state.supabase_client.table("users").insert({
            "username": username,
            "password_hash": password_hash
        }).execute()
        
        if response.data:
            return True, "íšŒì›ê°€ì…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
        else:
            return False, "íšŒì›ê°€ì…ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
    except Exception as e:
        error_msg = str(e)
        if "duplicate" in error_msg.lower() or "unique" in error_msg.lower():
            return False, "ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì‚¬ìš©ìëª…ì…ë‹ˆë‹¤."
        return False, f"íšŒì›ê°€ì… ì‹¤íŒ¨: {error_msg[:200]}"

def login_user(username: str, password: str) -> Tuple[bool, str]:
    """ì‚¬ìš©ì ë¡œê·¸ì¸ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    if not st.session_state.supabase_client:
        return False, "Supabase ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤."
    
    try:
        # ì‚¬ìš©ì ì¡°íšŒ
        response = st.session_state.supabase_client.table("users").select("*").eq("username", username).execute()
        
        if not response.data or len(response.data) == 0:
            return False, "ì‚¬ìš©ìëª… ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤."
        
        user = response.data[0]
        password_hash = hash_password(password)
        
        if user["password_hash"] == password_hash:
            return True, user["id"]
        else:
            return False, "ì‚¬ìš©ìëª… ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤."
    except Exception as e:
        return False, f"ë¡œê·¸ì¸ ì‹¤íŒ¨: {str(e)[:200]}"

# ============================================
# êµ¬ë¶„ì„  ë° ì·¨ì†Œì„  ì œê±° í•¨ìˆ˜
# ============================================
def remove_separators(text: str) -> str:
    """ë‹µë³€ì—ì„œ êµ¬ë¶„ì„ (---, ===, ___)ê³¼ ì·¨ì†Œì„ (~~í…ìŠ¤íŠ¸~~)ì„ ì œê±°í•©ë‹ˆë‹¤."""
    if not text:
        return text
    # ì·¨ì†Œì„  ë§ˆí¬ë‹¤ìš´ ì œê±°
    text = re.sub(r'~~([^~]+)~~', r'\1', text)
    # ì—¬ëŸ¬ ì¤„ì— ê±¸ì¹œ êµ¬ë¶„ì„  ì œê±°
    text = re.sub(r'\n\s*-{3,}\s*\n', '\n\n', text)
    text = re.sub(r'\n\s*={3,}\s*\n', '\n\n', text)
    text = re.sub(r'\n\s*_{3,}\s*\n', '\n\n', text)
    # ë‹¨ë… ë¼ì¸ì˜ êµ¬ë¶„ì„  ì œê±°
    text = re.sub(r'^\s*-{3,}\s*$', '', text, flags=re.MULTILINE)
    text = re.sub(r'^\s*={3,}\s*$', '', text, flags=re.MULTILINE)
    text = re.sub(r'^\s*_{3,}\s*$', '', text, flags=re.MULTILINE)
    # ì—°ì†ëœ ë¹ˆ ì¤„ ì •ë¦¬
    text = re.sub(r'\n{3,}', '\n\n', text)
    return text.strip()

# ============================================
# LLM ëª¨ë¸ ì„ íƒ í•¨ìˆ˜
# ============================================
def get_llm(model_name: str, temperature: float = 0.7):
    """ì„ íƒëœ ëª¨ë¸ëª…ì— ë”°ë¼ ì ì ˆí•œ LLM ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    # API í‚¤ëŠ” session_stateì—ì„œ ê°€ì ¸ì˜´
    if model_name == "gpt-5.1":
        api_key = st.session_state.get("openai_api_key") or os.getenv("OPENAI_API_KEY")
        if not api_key:
            st.error("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            st.stop()
        return ChatOpenAI(model="gpt-5.1", temperature=temperature, streaming=True, api_key=api_key)
    elif model_name == "claude-sonnet-4-5":
        if not ANTHROPIC_AVAILABLE:
            st.error("langchain_anthropicì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            st.stop()
        api_key = st.session_state.get("anthropic_api_key") or os.getenv("ANTHROPIC_API_KEY")
        if not api_key:
            st.error("Anthropic API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            st.stop()
        return ChatAnthropic(model="claude-sonnet-4-5", temperature=temperature, streaming=True, api_key=api_key)
    elif model_name == "gemini-3-pro-preview":
        if not GOOGLE_AVAILABLE:
            st.error("langchain_google_genaiê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            st.stop()
        api_key = st.session_state.get("gemini_api_key") or os.getenv("GOOGLE_API_KEY")
        if not api_key:
            st.error("Gemini API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            st.stop()
        return ChatGoogleGenerativeAI(
            model="gemini-3-pro-preview", 
            google_api_key=api_key, 
            temperature=temperature
        )
    else:
        api_key = st.session_state.get("openai_api_key") or os.getenv("OPENAI_API_KEY")
        if not api_key:
            st.error("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            st.stop()
        return ChatOpenAI(model="gpt-5.1", temperature=temperature, streaming=True, api_key=api_key)

# ============================================
# í˜ì´ì§€ ì„¤ì •
# ============================================
st.set_page_config(
    page_title="PDF ê¸°ë°˜ ë©€í‹°ìœ ì € ë©€í‹°ì„¸ì…˜ RAG ì±—ë´‡",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ============================================
if "supabase_client" not in st.session_state:
    st.session_state.supabase_client = init_supabase_client()

if "current_user_id" not in st.session_state:
    st.session_state.current_user_id = None

if "current_username" not in st.session_state:
    st.session_state.current_username = None

if "current_session_id" not in st.session_state:
    st.session_state.current_session_id = None

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "vectorstore_initialized" not in st.session_state:
    st.session_state.vectorstore_initialized = False

if "processed_files" not in st.session_state:
    st.session_state.processed_files = []

if "llm_model" not in st.session_state:
    st.session_state.llm_model = "gpt-5.1"

if "embeddings" not in st.session_state:
    # OpenAI API í‚¤ê°€ ìˆìœ¼ë©´ ì´ˆê¸°í™”
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        try:
            st.session_state.embeddings = OpenAIEmbeddings(api_key=api_key)
        except:
            st.session_state.embeddings = None
    else:
        st.session_state.embeddings = None

# API í‚¤ ì´ˆê¸°í™”
if "openai_api_key" not in st.session_state:
    st.session_state.openai_api_key = os.getenv("OPENAI_API_KEY", "")

if "anthropic_api_key" not in st.session_state:
    st.session_state.anthropic_api_key = os.getenv("ANTHROPIC_API_KEY", "")

if "gemini_api_key" not in st.session_state:
    st.session_state.gemini_api_key = os.getenv("GOOGLE_API_KEY", "")

# ============================================
# Supabase í—¬í¼ í•¨ìˆ˜
# ============================================
def get_all_sessions() -> List[Dict]:
    """í˜„ì¬ ì‚¬ìš©ìì˜ ëª¨ë“  ì„¸ì…˜ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    if not st.session_state.supabase_client or not st.session_state.current_user_id:
        return []
    try:
        response = st.session_state.supabase_client.table("sessions").select("*").eq("user_id", st.session_state.current_user_id).order("created_at", desc=True).execute()
        return response.data if response.data else []
    except Exception as e:
        logger.error(f"ì„¸ì…˜ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return []

def create_session(title: str) -> Tuple[Optional[str], Optional[str]]:
    """ìƒˆ ì„¸ì…˜ì„ ìƒì„±í•˜ê³  IDë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. (session_id, error_message)"""
    if not st.session_state.supabase_client:
        return None, "Supabase í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    if not st.session_state.current_user_id:
        return None, "ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."
    
    # title ê²€ì¦ ë° ì •ë¦¬
    if not title or not isinstance(title, str):
        title = f"ì„¸ì…˜ {datetime.now().strftime('%Y-%m-%d %H:%M')}"
    
    if len(title) > 500:
        title = title[:500]
    
    title = str(title).strip()
    if not title:
        title = f"ì„¸ì…˜ {datetime.now().strftime('%Y-%m-%d %H:%M')}"
    
    try:
        session_data = {
            "title": str(title).strip(),
            "user_id": st.session_state.current_user_id
        }
        
        if not session_data["title"]:
            session_data["title"] = f"ì„¸ì…˜ {datetime.now().strftime('%Y-%m-%d %H:%M')}"
        
        response = st.session_state.supabase_client.table("sessions").insert(session_data).execute()
        
        if response.data and len(response.data) > 0:
            session_id = response.data[0].get("id")
            if session_id:
                return str(session_id), None
            else:
                return None, "ì„¸ì…˜ ìƒì„± ì‘ë‹µì— IDê°€ ì—†ìŠµë‹ˆë‹¤."
        else:
            return None, "ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨: ì‘ë‹µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        error_msg = str(e)
        logger.error(f"ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨: {error_msg}")
        return None, f"ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨: {error_msg[:300]}"

def save_messages(session_id: str, messages: List[Dict]) -> Optional[str]:
    """ë©”ì‹œì§€ë¥¼ ì €ì¥í•©ë‹ˆë‹¤. ì„±ê³µ ì‹œ None, ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜."""
    if not st.session_state.supabase_client:
        return "Supabase í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    if not messages:
        return "ì €ì¥í•  ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    if not session_id:
        return "ì„¸ì…˜ IDê°€ ì—†ìŠµë‹ˆë‹¤."
    
    try:
        uuid.UUID(str(session_id))
    except (ValueError, TypeError):
        return f"ì„¸ì…˜ IDê°€ ì˜¬ë°”ë¥¸ UUID í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤: {session_id[:50]}"
    
    try:
        # ê¸°ì¡´ ë©”ì‹œì§€ ì‚­ì œ (ë®ì–´ì“°ê¸°)
        st.session_state.supabase_client.table("messages").delete().eq("session_id", session_id).execute()
        
        # ìƒˆ ë©”ì‹œì§€ ì €ì¥
        message_data = []
        for idx, msg in enumerate(messages):
            role = msg.get("role", "").strip().lower()
            if role not in ["user", "assistant"]:
                role = "user"
            
            content = msg.get("content", "")
            if not isinstance(content, str):
                content = str(content)
            
            if len(content) > 1000000:
                content = content[:1000000] + "\n\n[ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ì–´ ì¼ë¶€ê°€ ì˜ë ¸ìŠµë‹ˆë‹¤]"
            
            if content is None:
                content = ""
            
            message_data.append({
                "session_id": str(session_id),
                "role": role,
                "content": content,
                "message_order": int(idx)
            })
        
        if message_data:
            chunk_size = 500
            for i in range(0, len(message_data), chunk_size):
                batch = message_data[i:i + chunk_size]
                st.session_state.supabase_client.table("messages").insert(batch).execute()
        return None
    except Exception as e:
        error_msg = str(e)
        logger.error(f"ë©”ì‹œì§€ ì €ì¥ ì‹¤íŒ¨: {error_msg}")
        return f"ë©”ì‹œì§€ ì €ì¥ ì‹¤íŒ¨: {error_msg[:300]}"

def load_messages(session_id: str) -> List[Dict]:
    """ì„¸ì…˜ì˜ ë©”ì‹œì§€ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    if not st.session_state.supabase_client:
        return []
    try:
        response = st.session_state.supabase_client.table("messages").select("*").eq("session_id", session_id).order("message_order").execute()
        if response.data:
            return [{"role": msg["role"], "content": msg["content"]} for msg in response.data]
    except Exception as e:
        logger.error(f"ë©”ì‹œì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
    return []

def save_vector_documents(session_id: str, documents: List[Document], file_name: str):
    """ë²¡í„° ë¬¸ì„œë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
    if not st.session_state.supabase_client or not documents:
        return
    
    # embeddingsê°€ ì—†ìœ¼ë©´ ìƒì„±
    if not st.session_state.embeddings:
        api_key = st.session_state.get("openai_api_key") or os.getenv("OPENAI_API_KEY")
        if api_key:
            try:
                st.session_state.embeddings = OpenAIEmbeddings(api_key=api_key)
            except Exception as e:
                st.error(f"OpenAI API í‚¤ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {e}")
                return
        else:
            st.error("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
    
    try:
        # ê¸°ì¡´ ë¬¸ì„œ ì‚­ì œ (ê°™ì€ íŒŒì¼ëª…)
        st.session_state.supabase_client.table("vector_documents").delete().eq("session_id", session_id).eq("file_name", file_name).execute()
        
        # ì„ë² ë”© ìƒì„±
        texts = [doc.page_content for doc in documents]
        embeddings_list = st.session_state.embeddings.embed_documents(texts)
        
        # ë¬¸ì„œ ì €ì¥
        doc_data = []
        for idx, (doc, embedding) in enumerate(zip(documents, embeddings_list)):
            doc_data.append({
                "session_id": session_id,
                "file_name": file_name,
                "chunk_text": doc.page_content,
                "chunk_index": idx,
                "metadata": json.dumps(doc.metadata) if doc.metadata else "{}",
                "embedding": embedding
            })
        
        # ë°°ì¹˜ë¡œ ì €ì¥ (500ê°œì”©)
        chunk_size = 500
        for i in range(0, len(doc_data), chunk_size):
            batch = doc_data[i:i + chunk_size]
            st.session_state.supabase_client.table("vector_documents").insert(batch).execute()
    except Exception as e:
        logger.error(f"ë²¡í„° ë¬¸ì„œ ì €ì¥ ì‹¤íŒ¨: {e}")

def load_vector_documents(session_id: str) -> List[Document]:
    """ì„¸ì…˜ì˜ ë²¡í„° ë¬¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    if not st.session_state.supabase_client:
        return []
    try:
        response = st.session_state.supabase_client.table("vector_documents").select("*").eq("session_id", session_id).order("chunk_index").execute()
        if response.data:
            documents = []
            for row in response.data:
                metadata = json.loads(row["metadata"]) if row.get("metadata") else {}
                documents.append(Document(
                    page_content=row["chunk_text"],
                    metadata=metadata
                ))
            return documents
    except Exception as e:
        logger.error(f"ë²¡í„° ë¬¸ì„œ ë¡œë“œ ì‹¤íŒ¨: {e}")
    return []

def search_vector_documents(session_id: str, query: str, k: int = 5) -> List[Document]:
    """ë²¡í„° ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    if not st.session_state.supabase_client:
        return []
    
    # embeddingsê°€ ì—†ìœ¼ë©´ ìƒì„±
    if not st.session_state.embeddings:
        api_key = st.session_state.get("openai_api_key") or os.getenv("OPENAI_API_KEY")
        if api_key:
            try:
                st.session_state.embeddings = OpenAIEmbeddings(api_key=api_key)
            except Exception as e:
                logger.error(f"Embeddings ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                return []
        else:
            return []
    
    try:
        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query_embedding = st.session_state.embeddings.embed_query(query)
        
        # RPC í•¨ìˆ˜ í˜¸ì¶œ
        response = st.session_state.supabase_client.rpc(
            "match_documents",
            {
                "query_embedding": query_embedding,
                "match_count": k,
                "filter_session_id": session_id
            }
        ).execute()
        
        if response.data:
            documents = []
            for row in response.data:
                metadata = json.loads(row["metadata"]) if row.get("metadata") else {}
                documents.append(Document(
                    page_content=row["content"],
                    metadata=metadata
                ))
            return documents
    except Exception as e:
        logger.error(f"ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
    return []

def delete_session(session_id: str):
    """ì„¸ì…˜ì„ ì‚­ì œí•©ë‹ˆë‹¤."""
    if not st.session_state.supabase_client:
        return
    try:
        st.session_state.supabase_client.table("sessions").delete().eq("id", session_id).execute()
    except Exception as e:
        logger.error(f"ì„¸ì…˜ ì‚­ì œ ì‹¤íŒ¨: {e}")

def get_session_files(session_id: str) -> List[str]:
    """ì„¸ì…˜ì˜ íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    if not st.session_state.supabase_client:
        return []
    try:
        response = st.session_state.supabase_client.table("vector_documents").select("file_name").eq("session_id", session_id).execute()
        if response.data:
            return list(set([row["file_name"] for row in response.data]))
    except Exception as e:
        logger.error(f"íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
    return []

def generate_session_title(first_question: str, first_answer: str) -> str:
    """ì²« ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ê¸°ë°˜ìœ¼ë¡œ ì„¸ì…˜ ì œëª©ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        llm = get_llm(st.session_state.llm_model, temperature=0.7)
        prompt = f"""ë‹¤ìŒ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ìš”ì•½í•˜ì—¬ ê°„ê²°í•œ ì„¸ì…˜ ì œëª©ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {first_question}

ë‹µë³€: {first_answer[:500]}

ìš”êµ¬ì‚¬í•­:
- ì œëª©ì€ ìµœëŒ€ 30ì ì´ë‚´ë¡œ ì‘ì„±
- ì§ˆë¬¸ì˜ í•µì‹¬ ì£¼ì œë¥¼ ë°˜ì˜
- í•œê¸€ë¡œ ì‘ì„±
- ì„¤ëª… ì—†ì´ ì œëª©ë§Œ ë°˜í™˜

ì œëª©:"""
        response = llm.invoke(prompt)
        title = response.content.strip() if hasattr(response, 'content') else str(response).strip()
        if len(title) > 30:
            title = title[:30]
        return title
    except Exception as e:
        logger.error(f"ì„¸ì…˜ ì œëª© ìƒì„± ì‹¤íŒ¨: {e}")
        return f"ì„¸ì…˜ {datetime.now().strftime('%Y-%m-%d %H:%M')}"

# ============================================
# CSS ìŠ¤íƒ€ì¼
# ============================================
st.markdown("""
<style>
/* í—¤ë”© ìŠ¤íƒ€ì¼ */
h1 {
    font-size: 1.4rem !important;
    font-weight: 600 !important;
    color: #ff69b4 !important;
}
h2 {
    font-size: 1.2rem !important;
    font-weight: 600 !important;
    color: #ffd700 !important;
}
h3 {
    font-size: 1.1rem !important;
    font-weight: 600 !important;
    color: #1f77b4 !important;
}

/* ì±„íŒ… ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ */
.stChatMessage {
    font-size: 0.95rem !important;
    line-height: 1.5 !important;
}

.stChatMessage p {
    font-size: 0.95rem !important;
    line-height: 1.5 !important;
    margin: 0.5rem 0 !important;
}

/* ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
.stButton > button {
    background-color: #ff69b4 !important;
    color: white !important;
    border: none !important;
    border-radius: 5px !important;
    padding: 0.5rem 1rem !important;
    font-weight: bold !important;
}

.stButton > button:hover {
    background-color: #ff1493 !important;
}
</style>
""", unsafe_allow_html=True)

# ============================================
# ì œëª© ì˜ì—­
# ============================================
st.markdown("""
<div style="margin-top: -3rem; margin-bottom: 1rem;">
""", unsafe_allow_html=True)

col_title, col_empty = st.columns([4, 1])

with col_title:
    st.markdown("""
    <div style="text-align: center; margin-top: 0.5rem; margin-bottom: 0.5rem;">
        <h1 style="font-size: 7rem; font-weight: bold; margin: 0; line-height: 1.2;">
            <span style="color: #1f77b4;">PDF ê¸°ë°˜</span> 
            <span style="color: #ffd700;">ë©€í‹°ìœ ì €</span>
            <span style="color: #ff69b4;">ë©€í‹°ì„¸ì…˜</span>
            <span style="color: #1f77b4;">RAG ì±—ë´‡</span>
        </h1>
    </div>
    """, unsafe_allow_html=True)

with col_empty:
    st.empty()

st.markdown("</div>", unsafe_allow_html=True)

# ============================================
# ì‚¬ì´ë“œë°”
# ============================================
with st.sidebar:
    # API í‚¤ ì…ë ¥ (ìƒë‹¨)
    st.title("ğŸ”‘ API í‚¤ ì„¤ì •")
    st.markdown("---")
    
    openai_key = st.text_input(
        "OpenAI API Key",
        value=st.session_state.openai_api_key,
        type="password",
        help="OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
    )
    st.session_state.openai_api_key = openai_key
    if openai_key:
        os.environ["OPENAI_API_KEY"] = openai_key
        # embeddings ì—…ë°ì´íŠ¸
        try:
            st.session_state.embeddings = OpenAIEmbeddings(api_key=openai_key)
        except Exception as e:
            logger.warning(f"Embeddings ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    anthropic_key = st.text_input(
        "Anthropic API Key",
        value=st.session_state.anthropic_api_key,
        type="password",
        help="Anthropic API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
    )
    st.session_state.anthropic_api_key = anthropic_key
    if anthropic_key:
        os.environ["ANTHROPIC_API_KEY"] = anthropic_key
    
    gemini_key = st.text_input(
        "Gemini API Key",
        value=st.session_state.gemini_api_key,
        type="password",
        help="Google Gemini API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
    )
    st.session_state.gemini_api_key = gemini_key
    if gemini_key:
        os.environ["GOOGLE_API_KEY"] = gemini_key
    
    st.markdown("---")
    
    # ë¡œê·¸ì¸/íšŒì›ê°€ì…
    st.title("ğŸ‘¤ ì‚¬ìš©ì ì¸ì¦")
    st.markdown("---")
    
    if not st.session_state.current_user_id:
        # ë¡œê·¸ì¸ë˜ì§€ ì•Šì€ ìƒíƒœ
        tab1, tab2 = st.tabs(["ë¡œê·¸ì¸", "íšŒì›ê°€ì…"])
        
        with tab1:
            login_username = st.text_input("ì‚¬ìš©ìëª…", key="login_username")
            login_password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="login_password")
            
            if st.button("ë¡œê·¸ì¸", use_container_width=True):
                if login_username and login_password:
                    success, result = login_user(login_username, login_password)
                    if success:
                        st.session_state.current_user_id = result
                        st.session_state.current_username = login_username
                        st.success("ë¡œê·¸ì¸ ì„±ê³µ!")
                        st.rerun()
                    else:
                        st.error(result)
                else:
                    st.error("ì‚¬ìš©ìëª…ê³¼ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        with tab2:
            reg_username = st.text_input("ì‚¬ìš©ìëª…", key="reg_username")
            reg_password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="reg_password")
            reg_password_confirm = st.text_input("ë¹„ë°€ë²ˆí˜¸ í™•ì¸", type="password", key="reg_password_confirm")
            
            if st.button("íšŒì›ê°€ì…", use_container_width=True):
                if reg_username and reg_password:
                    if reg_password != reg_password_confirm:
                        st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    else:
                        success, message = register_user(reg_username, reg_password)
                        if success:
                            st.success(message)
                        else:
                            st.error(message)
                else:
                    st.error("ëª¨ë“  í•„ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        # ë¡œê·¸ì¸ëœ ìƒíƒœ
        st.success(f"ë¡œê·¸ì¸: {st.session_state.current_username}")
        if st.button("ë¡œê·¸ì•„ì›ƒ", use_container_width=True):
            st.session_state.current_user_id = None
            st.session_state.current_username = None
            st.session_state.current_session_id = None
            st.session_state.chat_history = []
            st.session_state.vectorstore_initialized = False
            st.session_state.processed_files = []
            st.rerun()
    
    st.markdown("---")
    
    # Supabase ì—°ê²° í™•ì¸
    if not st.session_state.supabase_client:
        st.error("âš ï¸ Supabase ì—°ê²° ì‹¤íŒ¨")
        supabase_url = os.getenv("SUPABASE_URL")
        supabase_key = os.getenv("SUPABASE_ANON_KEY") or os.getenv("SUPABASE_KEY")
        
        if not supabase_url:
            st.error("âŒ SUPABASE_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        if not supabase_key:
            st.error("âŒ SUPABASE_ANON_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    # ë¡œê·¸ì¸ëœ ê²½ìš°ì—ë§Œ ì„¸ì…˜ ê´€ë¦¬ ë° ê¸°íƒ€ ê¸°ëŠ¥ í‘œì‹œ
    if st.session_state.current_user_id:
        # LLM ëª¨ë¸ ì„ íƒ
        st.markdown('<h2 style="color: #1f77b4;">LLM ëª¨ë¸ ì„ íƒ</h2>', unsafe_allow_html=True)
        all_models = ["gpt-5.1", "claude-sonnet-4-5", "gemini-3-pro-preview"]
        selected_model = st.radio(
            "ì‚¬ìš©í•  ì–¸ì–´ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”",
            options=all_models,
            index=all_models.index(st.session_state.llm_model) if st.session_state.llm_model in all_models else 0,
            key='llm_model_radio'
        )
        st.session_state.llm_model = selected_model
        
        st.markdown("---")
        
        # ì„¸ì…˜ ê´€ë¦¬
        st.markdown('<h2 style="color: #ffd700;">ì„¸ì…˜ ê´€ë¦¬</h2>', unsafe_allow_html=True)
        
        # ì„¸ì…˜ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        sessions = get_all_sessions()
        session_options = ["ìƒˆ ì„¸ì…˜"] + [f"{s['title']} ({s['id'][:8]}...)" for s in sessions]
        session_ids = [None] + [s['id'] for s in sessions]
        
        if "last_selected_session_idx" not in st.session_state:
            st.session_state.last_selected_session_idx = 0
        
        selected_session_idx = st.selectbox(
            "ì„¸ì…˜ ì„ íƒ",
            range(len(session_options)),
            format_func=lambda x: session_options[x],
            key="session_selectbox",
            index=st.session_state.last_selected_session_idx
        )
        
        # ì„¸ì…˜ ì„ íƒì´ ë³€ê²½ë˜ë©´ ìë™ìœ¼ë¡œ ë¡œë“œ
        if selected_session_idx != st.session_state.last_selected_session_idx:
            st.session_state.last_selected_session_idx = selected_session_idx
            if selected_session_idx > 0:
                selected_session_id = session_ids[selected_session_idx]
                st.session_state.current_session_id = selected_session_id
                
                # ë©”ì‹œì§€ ë¡œë“œ
                messages = load_messages(selected_session_id)
                st.session_state.chat_history = messages
                
                # ë²¡í„° ë¬¸ì„œ ë¡œë“œ
                documents = load_vector_documents(selected_session_id)
                if documents:
                    st.session_state.vectorstore_initialized = True
                    st.session_state.processed_files = get_session_files(selected_session_id)
                else:
                    st.session_state.vectorstore_initialized = False
                    st.session_state.processed_files = []
                
                st.rerun()
        
        # ì„¸ì…˜ ë¡œë“œ ë²„íŠ¼
        if st.button("ğŸ“‚ ì„¸ì…˜ ë¡œë“œ", use_container_width=True):
            if selected_session_idx > 0:
                selected_session_id = session_ids[selected_session_idx]
                st.session_state.current_session_id = selected_session_id
                
                messages = load_messages(selected_session_id)
                st.session_state.chat_history = messages
                
                documents = load_vector_documents(selected_session_id)
                if documents:
                    st.session_state.vectorstore_initialized = True
                    st.session_state.processed_files = get_session_files(selected_session_id)
                else:
                    st.session_state.vectorstore_initialized = False
                    st.session_state.processed_files = []
                
                st.success(f"ì„¸ì…˜ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤: {sessions[selected_session_idx-1]['title']}")
                st.rerun()
            else:
                st.warning("ì„¸ì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        
        # ì„¸ì…˜ ì €ì¥ ë²„íŠ¼
        if st.button("ğŸ’¾ ì„¸ì…˜ ì €ì¥", use_container_width=True):
            if not st.session_state.supabase_client:
                st.error("âš ï¸ Supabase ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            elif len(st.session_state.chat_history) >= 2:
                with st.spinner("ì„¸ì…˜ ì €ì¥ ì¤‘..."):
                    first_question = st.session_state.chat_history[0]["content"] if st.session_state.chat_history[0]["role"] == "user" else ""
                    first_answer = st.session_state.chat_history[1]["content"] if len(st.session_state.chat_history) > 1 and st.session_state.chat_history[1]["role"] == "assistant" else ""
                    
                    if first_question and first_answer:
                        try:
                            title = generate_session_title(first_question, first_answer)
                        except Exception as e:
                            logger.warning(f"ì„¸ì…˜ ì œëª© ìƒì„± ì‹¤íŒ¨: {e}")
                            title = f"ì„¸ì…˜ {datetime.now().strftime('%Y-%m-%d %H:%M')}"
                    else:
                        title = f"ì„¸ì…˜ {datetime.now().strftime('%Y-%m-%d %H:%M')}"
                    
                    if st.session_state.current_session_id:
                        session_id = st.session_state.current_session_id
                        error_msg = None
                        try:
                            uuid.UUID(str(session_id))
                        except (ValueError, TypeError):
                            st.warning(f"í˜„ì¬ ì„¸ì…˜ IDê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ìƒˆ ì„¸ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.")
                            session_id, error_msg = create_session(title)
                            if session_id:
                                st.session_state.current_session_id = session_id
                    else:
                        session_id, error_msg = create_session(title)
                        if session_id:
                            st.session_state.current_session_id = session_id
                    
                    if error_msg:
                        st.error(f"ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨: {error_msg}")
                    elif session_id:
                        try:
                            uuid.UUID(str(session_id))
                        except (ValueError, TypeError):
                            st.error(f"ì„¸ì…˜ ID í˜•ì‹ ì˜¤ë¥˜: {session_id[:50]}")
                            st.stop()
                        
                        save_error = save_messages(session_id, st.session_state.chat_history)
                        
                        if save_error:
                            st.error(f"ë©”ì‹œì§€ ì €ì¥ ì‹¤íŒ¨: {save_error}")
                        else:
                            st.success(f"âœ… ì„¸ì…˜ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {title}")
                            st.rerun()
                    else:
                        st.error("ì„¸ì…˜ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            else:
                st.warning("ì €ì¥í•  ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤. ìµœì†Œ 1ê°œì˜ ì§ˆë¬¸ê³¼ ë‹µë³€ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ì„¸ì…˜ ì‚­ì œ ë²„íŠ¼
        if st.button("ğŸ—‘ï¸ ì„¸ì…˜ ì‚­ì œ", use_container_width=True):
            if st.session_state.current_session_id:
                delete_session(st.session_state.current_session_id)
                st.session_state.current_session_id = None
                st.session_state.chat_history = []
                st.session_state.vectorstore_initialized = False
                st.session_state.processed_files = []
                st.success("ì„¸ì…˜ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.rerun()
            else:
                st.warning("ì‚­ì œí•  ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # í™”ë©´ ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ğŸ”„ í™”ë©´ ì´ˆê¸°í™”", use_container_width=True):
            st.session_state.chat_history = []
            st.session_state.current_session_id = None
            st.session_state.vectorstore_initialized = False
            st.session_state.processed_files = []
            st.rerun()
        
        # VectorDB íŒŒì¼ ëª©ë¡ ë³´ê¸°
        if st.button("ğŸ“‹ VectorDB", use_container_width=True):
            if st.session_state.current_session_id:
                files = get_session_files(st.session_state.current_session_id)
                if files:
                    st.info("**í˜„ì¬ ì„¸ì…˜ì˜ íŒŒì¼ ëª©ë¡:**")
                    for file in files:
                        st.write(f"- {file}")
                else:
                    st.info("í˜„ì¬ ì„¸ì…˜ì— ì €ì¥ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.warning("ì„¸ì…˜ì„ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”.")
        
        st.markdown("---")
        
        # PDF íŒŒì¼ ì—…ë¡œë“œ
        st.markdown('<h2 style="color: #ff69b4;">PDF íŒŒì¼ ì—…ë¡œë“œ</h2>', unsafe_allow_html=True)
        uploaded_files = st.file_uploader(
            "PDF íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
            type=["pdf"],
            accept_multiple_files=True,
            key="pdf_uploader"
        )
        
        if uploaded_files and st.button("íŒŒì¼ ì²˜ë¦¬í•˜ê¸°"):
            if not st.session_state.current_session_id:
                session_id, _ = create_session(f"ì„¸ì…˜ {datetime.now().strftime('%Y-%m-%d %H:%M')}")
                if session_id:
                    st.session_state.current_session_id = session_id
                else:
                    st.error("ì„¸ì…˜ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    st.stop()
            
            if st.session_state.current_session_id:
                with st.spinner("PDF íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘..."):
                    all_docs = []
                    new_files = []
                    
                    for uploaded_file in uploaded_files:
                        if uploaded_file.name in st.session_state.processed_files:
                            continue
                        
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                            tmp_file.write(uploaded_file.read())
                            tmp_path = tmp_file.name
                        
                        try:
                            loader = PyPDFLoader(tmp_path)
                            docs = loader.load()
                            for doc in docs:
                                doc.metadata["source"] = uploaded_file.name
                            all_docs.extend(docs)
                            new_files.append(uploaded_file.name)
                        except Exception as e:
                            st.error(f"íŒŒì¼ {uploaded_file.name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                        finally:
                            if os.path.exists(tmp_path):
                                os.remove(tmp_path)
                    
                    if all_docs:
                        text_splitter = RecursiveCharacterTextSplitter(
                            chunk_size=1000,
                            chunk_overlap=200
                        )
                        chunks = text_splitter.split_documents(all_docs)
                        
                        file_chunks = {}
                        for chunk in chunks:
                            file_name = chunk.metadata.get("source", "unknown.pdf")
                            if file_name not in file_chunks:
                                file_chunks[file_name] = []
                            file_chunks[file_name].append(chunk)
                        
                        for file_name, file_chunk_list in file_chunks.items():
                            save_vector_documents(st.session_state.current_session_id, file_chunk_list, file_name)
                        
                        st.session_state.processed_files.extend(new_files)
                        st.session_state.vectorstore_initialized = True
                        st.success(f"âœ… {len(chunks)}ê°œì˜ ë¬¸ì„œ ì²­í¬ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.rerun()
                    else:
                        st.warning("ì²˜ë¦¬í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ë¡œê·¸ì¸ í›„ ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥ì…ë‹ˆë‹¤.")

# ============================================
# ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
# ============================================
if not st.session_state.current_user_id:
    st.info("ğŸ‘† ì‚¬ì´ë“œë°”ì—ì„œ ë¡œê·¸ì¸í•´ì£¼ì„¸ìš”.")
else:
    # ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    for message in st.session_state.chat_history:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # ë‹µë³€ ìƒì„±
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            
            try:
                # RAG ì‚¬ìš© ì—¬ë¶€ í™•ì¸
                use_rag = st.session_state.vectorstore_initialized and st.session_state.current_session_id
                
                if use_rag:
                    # RAG ê²€ìƒ‰
                    retrieved_docs = search_vector_documents(st.session_state.current_session_id, prompt, k=5)
                    
                    if retrieved_docs:
                        context_text = "\n\n".join([doc.page_content for doc in retrieved_docs[:3]])
                        
                        system_prompt = f"""ë„ˆëŠ” ë§¤ìš° ì¹œì ˆí•œ ì„ ìƒë‹˜ì´ì•¼. ë‹µë³€ì€ ë§¤ìš° ì‰½ê²Œ ì¤‘í•™ìƒ ë ˆë²¨ì—ì„œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í•´ì¤˜. 
ê·¸ëŸ¬ë‚˜ ë‚´ìš©ì€ ìƒëµí•˜ëŠ” ê²ƒ ì—†ì´ ëª¨ë‘ ë‹µì„ í•´ì¤˜. ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  ë‹µí•´ì¤˜. ë§íˆ¬ëŠ” ì¡´ëŒ€ë§ í•œê¸€ë¡œ í•´ì¤˜.

ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸:
{context_text}

ì§ˆë¬¸: {prompt}

ë‹µë³€ í˜•ì‹:
- ë‹µë³€ì€ ë°˜ë“œì‹œ ì œëª©ê³¼ ë³¸ë¬¸ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”
- ì œëª©(# H1)ì€ ì§ˆë¬¸ì˜ í•µì‹¬ì„ ì§§ê³  ëª…í™•í•˜ê²Œ ìš”ì•½í•œ í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš” (ìµœëŒ€ 20ì ì´ë‚´ ê¶Œì¥)
- ì œëª© ë‹¤ìŒì— ë¹ˆ ì¤„ì„ í•˜ë‚˜ ë‘ê³  ë³¸ë¬¸ì„ ì‘ì„±í•˜ì„¸ìš”
- ë³¸ë¬¸ì€ ## (H2)ì™€ ### (H3) í—¤ë”©ì„ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡°í™”í•˜ì„¸ìš”
- ë³¸ë¬¸ì€ ì„œìˆ í˜•ìœ¼ë¡œ ì‘ì„±í•˜ë˜ ì¡´ëŒ€ë§ì„ ì‚¬ìš©í•˜ì„¸ìš”
- ê°œì¡°ì‹ì´ë‚˜ ë¶ˆì™„ì „í•œ ë¬¸ì¥ì„ ì‚¬ìš©í•˜ì§€ ë§ê³ , ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ì„œìˆ í•˜ì„¸ìš”

ì£¼ì˜ì‚¬í•­:
- ë‹µë³€ ì¤‘ê°„ì— êµ¬ë¶„ì„ (---, ===, ___)ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
- ë§ˆí¬ë‹¤ìš´ êµ¬ë¶„ì„ ì´ë‚˜ ì„ ì„ ê·¸ë¦¬ëŠ” ê¸°í˜¸ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
- ì·¨ì†Œì„ (~~í…ìŠ¤íŠ¸~~)ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”"""
                    else:
                        system_prompt = f"""ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {prompt}

ë‹µë³€ í˜•ì‹:
- ë‹µë³€ì€ ë°˜ë“œì‹œ ì œëª©ê³¼ ë³¸ë¬¸ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”
- ì œëª©(# H1)ì€ ì§ˆë¬¸ì˜ í•µì‹¬ì„ ì§§ê³  ëª…í™•í•˜ê²Œ ìš”ì•½í•œ í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš” (ìµœëŒ€ 20ì ì´ë‚´ ê¶Œì¥)
- ì œëª© ë‹¤ìŒì— ë¹ˆ ì¤„ì„ í•˜ë‚˜ ë‘ê³  ë³¸ë¬¸ì„ ì‘ì„±í•˜ì„¸ìš”
- ë³¸ë¬¸ì€ ## (H2)ì™€ ### (H3) í—¤ë”©ì„ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡°í™”í•˜ì„¸ìš”
- ë³¸ë¬¸ì€ ì„œìˆ í˜•ìœ¼ë¡œ ì‘ì„±í•˜ë˜ ì¡´ëŒ€ë§ì„ ì‚¬ìš©í•˜ì„¸ìš”
- ê°œì¡°ì‹ì´ë‚˜ ë¶ˆì™„ì „í•œ ë¬¸ì¥ì„ ì‚¬ìš©í•˜ì§€ ë§ê³ , ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ì„œìˆ í•˜ì„¸ìš”

ì£¼ì˜ì‚¬í•­:
- ë‹µë³€ ì¤‘ê°„ì— êµ¬ë¶„ì„ (---, ===, ___)ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
- ë§ˆí¬ë‹¤ìš´ êµ¬ë¶„ì„ ì´ë‚˜ ì„ ì„ ê·¸ë¦¬ëŠ” ê¸°í˜¸ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
- ì·¨ì†Œì„ (~~í…ìŠ¤íŠ¸~~)ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”"""
                else:
                    system_prompt = f"""ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {prompt}

ë‹µë³€ í˜•ì‹:
- ë‹µë³€ì€ ë°˜ë“œì‹œ ì œëª©ê³¼ ë³¸ë¬¸ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”
- ì œëª©(# H1)ì€ ì§ˆë¬¸ì˜ í•µì‹¬ì„ ì§§ê³  ëª…í™•í•˜ê²Œ ìš”ì•½í•œ í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš” (ìµœëŒ€ 20ì ì´ë‚´ ê¶Œì¥)
- ì œëª© ë‹¤ìŒì— ë¹ˆ ì¤„ì„ í•˜ë‚˜ ë‘ê³  ë³¸ë¬¸ì„ ì‘ì„±í•˜ì„¸ìš”
- ë³¸ë¬¸ì€ ## (H2)ì™€ ### (H3) í—¤ë”©ì„ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡°í™”í•˜ì„¸ìš”
- ë³¸ë¬¸ì€ ì„œìˆ í˜•ìœ¼ë¡œ ì‘ì„±í•˜ë˜ ì¡´ëŒ€ë§ì„ ì‚¬ìš©í•˜ì„¸ìš”
- ê°œì¡°ì‹ì´ë‚˜ ë¶ˆì™„ì „í•œ ë¬¸ì¥ì„ ì‚¬ìš©í•˜ì§€ ë§ê³ , ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ì„œìˆ í•˜ì„¸ìš”

ì£¼ì˜ì‚¬í•­:
- ë‹µë³€ ì¤‘ê°„ì— êµ¬ë¶„ì„ (---, ===, ___)ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
- ë§ˆí¬ë‹¤ìš´ êµ¬ë¶„ì„ ì´ë‚˜ ì„ ì„ ê·¸ë¦¬ëŠ” ê¸°í˜¸ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
- ì·¨ì†Œì„ (~~í…ìŠ¤íŠ¸~~)ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”"""
                
                # LLMìœ¼ë¡œ ë‹µë³€ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°)
                llm = get_llm(st.session_state.llm_model, temperature=1)
                
                # ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¡œ ë‹µë³€ ìƒì„±
                if hasattr(llm, 'stream'):
                    for chunk in llm.stream(system_prompt):
                        if hasattr(chunk, 'content'):
                            chunk_text = chunk.content
                        else:
                            chunk_text = str(chunk)
                        full_response += chunk_text
                        cleaned_response = remove_separators(full_response)
                        message_placeholder.markdown(cleaned_response)
                else:
                    response = llm.invoke(system_prompt)
                    full_response = response.content if hasattr(response, 'content') else str(response)
                    cleaned_response = remove_separators(full_response)
                    message_placeholder.markdown(cleaned_response)
                
                # ë‹µë³€ ì •ë¦¬
                full_response = remove_separators(full_response)
                
                # ë‹¤ìŒ ì§ˆë¬¸ 3ê°œ ìƒì„±
                try:
                    next_questions_prompt = f"""
ì§ˆë¬¸ìê°€ í•œ ì§ˆë¬¸: {prompt}

ìƒì„±ëœ ë‹µë³€:
{full_response}

ìœ„ ì§ˆë¬¸ê³¼ ë‹µë³€ ë‚´ìš©ì„ ê²€í† í•˜ì—¬, ì§ˆë¬¸ìê°€ ë‹¤ìŒì— í•  ìˆ˜ ìˆëŠ” ì¤‘ìš”í•œ 3ê°€ì§€ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

ìš”êµ¬ì‚¬í•­:
- ë‹µë³€ ë‚´ìš©ì„ ë” ê¹Šì´ ì´í•´í•˜ê¸° ìœ„í•œ í›„ì† ì§ˆë¬¸
- ë‹µë³€ì—ì„œ ì–¸ê¸‰ëœ ë‚´ìš©ì„ êµ¬ì²´í™”í•˜ê±°ë‚˜ í™•ì¥í•˜ëŠ” ì§ˆë¬¸
- ê´€ë ¨ëœ ë‹¤ë¥¸ ì£¼ì œë‚˜ ê´€ì ì„ íƒìƒ‰í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸
- ê° ì§ˆë¬¸ì€ ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ë˜, ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±
- ì§ˆë¬¸ì€ ë²ˆí˜¸ ì—†ì´ ìˆœì„œëŒ€ë¡œ ë‚˜ì—´í•˜ë˜, ê° ì§ˆë¬¸ì€ ë³„ë„ì˜ ì¤„ì— ì‘ì„±

í˜•ì‹:
ì§ˆë¬¸1
ì§ˆë¬¸2
ì§ˆë¬¸3

ì°¸ê³ : ì§ˆë¬¸ë§Œ ì‘ì„±í•˜ê³ , ì„¤ëª…ì´ë‚˜ ì¶”ê°€ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
"""
                    next_questions_response = llm.invoke(next_questions_prompt)
                    next_questions_text = next_questions_response.content if hasattr(next_questions_response, 'content') else str(next_questions_response)
                    next_questions = [q.strip() for q in next_questions_text.strip().split('\n') if q.strip() and not q.strip().startswith('#')]
                    next_questions = next_questions[:3]
                    
                    if next_questions:
                        full_response += "\n\n"
                        full_response += "### ğŸ’¡ ë‹¤ìŒì— ë¬¼ì–´ë³¼ ìˆ˜ ìˆëŠ” ì§ˆë¬¸ë“¤\n\n"
                        for i, question in enumerate(next_questions, 1):
                            full_response += f"{i}. {question}\n\n"
                        
                        message_placeholder.markdown(full_response)
                except Exception as e:
                    logger.warning(f"ë‹¤ìŒ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")
                
                # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
                st.session_state.chat_history.append({"role": "assistant", "content": full_response})
                
                # ìë™ ì €ì¥ (ì²« ì§ˆë¬¸ê³¼ ë‹µë³€ì´ ìˆìœ¼ë©´)
                if len(st.session_state.chat_history) == 2 and not st.session_state.current_session_id:
                    first_question = st.session_state.chat_history[0]["content"]
                    first_answer = st.session_state.chat_history[1]["content"]
                    title = generate_session_title(first_question, first_answer)
                    session_id, _ = create_session(title)
                    if session_id:
                        st.session_state.current_session_id = session_id
                        save_messages(session_id, st.session_state.chat_history)
                elif st.session_state.current_session_id:
                    # ê¸°ì¡´ ì„¸ì…˜ì— ë©”ì‹œì§€ ì €ì¥ (ìë™ ì €ì¥)
                    save_messages(st.session_state.current_session_id, st.session_state.chat_history)
            
            except Exception as e:
                error_msg = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                message_placeholder.markdown(error_msg)
                st.session_state.chat_history.append({"role": "assistant", "content": error_msg})
                logger.error(f"ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")

